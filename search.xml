<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[高性能MySQL]]></title>
    <url>%2F2019%2F07%2F08%2F%E9%AB%98%E6%80%A7%E8%83%BDMySQL%2F</url>
    <content type="text"><![CDATA[1、MySQL架构1、逻辑架构1、最上层：连接管理、授权认证、安全等。每个客户端在服务器进程中都有一个线程，这个连接的查询只会在这个单独的线程中执行，该线程轮流在某个CPU核心或者CPU运行。2、第二层：MySQL核心功能，包括解析、分析、优化、缓存以及所有内置函数（日期、时间、数学和加密函数），跨存储引擎的功能包括存储过程、触发器、视图等。3、第三层：存储引擎，负责数据存储和提取。 2、并发控制1、读写锁 读：共享锁 写：排他锁2、锁粒度 表锁：开销小 行级锁：开销大，最大程度支持并发3、事务 1、事务特性：ACID2、SQL定义的四种隔离级别 未提交读：事务中的没有提交的修改对其他事务也是可见的；可能出现：脏读、不可重复读、幻读。 提交读：事务所做的修改在未提交之前对其他事务时不可见的；也叫不可重复读，两次执行同样的查询可能得到不同的结果。可能出现：不可重复读、幻读。 可重复读（MySQL默认事务隔离级别）：保证在同一个事务中多次读取同样记录的结果是一样的。可能出现：幻读（某个事务读取某个范围内的记录另一个事务又在该范围内插入新的记录，当之前的事务再次读取该范围的记录时会产生幻行）。 可串行化：最高隔离级别，强制事务串行执行，在读取每一行数据上都加锁。3、InnoDB采用多版本并发控制（MVCC）解决幻读；InnoDB解决死锁：回滚持有最少行级排他锁的事务。MVCC只能在可重复读和提交读两个隔离级别下工作。MVCC是通过保存数据在某个时间点的快照来实现的。4、存储引擎 1、InnoDB的间隙锁：锁住一个范围内的索引记录，或者锁住第一条索引记录之前的范围，又或者锁住最后一条索引记录之后的范围。间隙锁可能包含单个索引或者多个索引或者不包含索引都可以。 一个事务占用的间隙锁不会阻止另一个事务在同一个间隙上获得间隙锁； 如果有唯一索引，利用唯一索引查询某一行的数据不会产生间隙锁；如果没有索引或者是非唯一索引，当查询某一行数据时会产生间隙锁把所查询的行之前的所有行锁住。 间隙锁策略防止幻读的出现，间隙锁锁定查询涉及的行和对索引中的间隙进行锁定，以防止幻影行的插入。2、MyISAM和InnoDB的区别 InnoDB支持事务，MyISAM不支持事务； MyISAM只支持表锁，InnoDB支持表锁行级锁； MyISAM不支持外键，InnoDB支持外键； MyISAM允许没有主键，InnoDB如果没有设置主键会自动创建默认主键（6字节）； MyISAM支持全文搜索，MySQL5.6后InnoDB才支持全文搜索； MyISAM有专门的计数器记录数据库表的行数，InnoDB没有。2、Schema和数据类型 1、选择优化的数据类型1、更小的通常更好，尽量使用可以正确存储数据的最小数据类型。更小的数据类型通常更快，因为他们占用更少的磁盘、内存和CPU缓存，并且处理时需要的CPU周期更少。2、简单的更好，简单数据类型的操作通常需要更少的CPU周期，比如，整型比字符操作代价更低。使用内建类型而不是字符串来存储日期，使用整型存储IP。3、尽量避免NULL的列，除非真正需要，因为查询中如果包含NULL的列对MySQL来说很难优化4、TIMESAMP和DATETIME都可以存储相同类型的数据，但是TIMESAMP使用DATETIME一半的存储空间，会根据时区自动更新。5、VARCHAR存储可变长字符串，下面的情况适合VARCHAR：字符串列的最大长度比平均长度大的多；列的更新很少，所以碎片不是问题；使用了UTF-8这杨复杂的字符集，每个字符都使用了不同的字节数进行存储。6、CHAR类型是定长的，适合存储很短的字符串，或者所有值都接近同一个长度。7、BLOB和TEXT未存储很大的数据设计的字符串数据类型，分别采用二进制和字符方式存储。8、整数时标识列最好的选择，因为很快并且支持自增；尽量避免字符串类型作为标识列，因为耗空间，比数字类型慢。完全随机的字符串，例如MD5、UUID等产生的字符串会任意分布在很大的空间，因为插入值会随机写到索引的不同位置，导致页分裂、磁盘随机访问，以及聚簇存储引擎产生聚簇索引碎片，使得INSERT变得很慢。逻辑上相邻的行分布在磁盘和内存的不同地方，所以SELECT语句变得很慢。随机值导致缓存对所有类型的查询语句效果都很差，因为会使得缓存赖以工作的访问局部性原理失效。 2、MySQL Schema设计中的陷阱1、太多的列，存储引擎API工作时需要在服务器层和存储引擎层之间通过行缓冲拷贝数据，然后在服务器层将缓冲内容解码成各个列，太多的列导致解码代价高。2、太多的关联，如果希望查询执行快速且并发性好，单个查询最好在12个表内关联。 3、范式与反范式1、范式是设计数据库时遵循的一些规则。 1NF：数据表的每一列都是不可再分的基本数据项。 2NF：数据表每行必须可以被唯一区分，通常使用一个主键来唯一标识。 3NF：非主属性之间不能相互依赖，必须直接依赖候选关键字。2、反范式 增加冗余列：在多个表中增加相同的列，为了避免查询时连接操作； 增加派生列：增加的列来自其他表的数据，是由其他表经过计算生成，减少查询时的连接操作； 重新组表和分割表3、范式的优点 更新更快； 很少或者没有重复数据，所以只需修改更少的数据； 表更小，可以更好的存放在内存，执行操作更快； 很少多余的数据意味着检索时更少用到DISTINCT或者GROUP BY语句。缺点：需要关联。4、ALTER TABLE操作常见场景： 先在一台不提供服务的机器上执行ALTER TABLE操作，然后和提供服务的主库切换； “影子拷贝”，用要求的表结构创建一张与源表无关的新表，然后通过重命名和删表操作交换两张表。3、创建高性能索引 索引是存储引擎用于快速找到记录的一种数据结构。 1、索引的类型1、B-TREE B-TREE对索引列是顺序组织存储的，所以适合范围查找； B-TREE索引的限制： 要按照索引的最左列开始查找，否则无法使用索引； 不能跳过索引中的列，比如索引是三个列，无法按照第一列和第三列使用索引； 如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找。2、哈希索引：基于哈希表实现，只有精确匹配索引所有列的查询才有效。 对索引列计算哈希值，存储在索引中，同时在哈希表中存储指向每个数据行的指针； 哈希索引的限制： 索引数据不是按照索引值顺序存储的，无法用于排序； 不支持部分索引列匹配查找； 只支持等值比较查询，不支持任何范围查询； 如果哈希冲突很多的话，一些索引维护操作代价很高； 当查询时出现哈希冲突时，存储引擎必须遍历链表中的所有指针逐行进行比较直到找到符合条件的行。 InnoDB支持自适应的哈希索引，对某些使用频繁的索引值创建哈希索引；这是存储引擎完全自动、内部的行为；3、全文索引：查找文本中的关键词。2、索引的优点 1、大大减少了服务器需要扫描的数据量；2、帮助服务器避免排序和临时表；3、将随机IO变为顺序IO； 3、高性能的索引策略1、独立的列：如果查询中的列不是独立的，MySQL不会使用索引，独立的列就是索引列不能是表达式的一部分，也不能是函数的一部分。2、索引的选择性：不重复的索引值和数据表总记录数的比值。选择性越高查询效率越高，因为MySQL会在查询时过滤掉很多行。3、前缀索引：索引开始的部分字符，可以大大节约索引空间，提高索引效率。缺点：MySQL不能用前缀索引做ORDER BY和Group By，也无法使用前缀索引做覆盖扫描。常见应用场景：针对很长的十六进制唯一ID使用前缀索引。4、索引合并策略有时候是一种优化的结果： 当服务器对多个索引做相交操作（通常是有多个AND条件）意味着需要的是一个包含所有相关列的多列索引，而不是多个独立的索引； 当服务器对多个索引做联合操作时（通常是多个OR条件）通常需要耗费大量CPU和内存资源在算法的缓存、排序和合并。5、聚簇索引：不是一种单独的索引，而是一种数据存储方式。InnoDB的聚簇索引实际上是在同一个结构中保存了B+TREE索引和数据行，叶子页包含了行的全部数据，节点页只包含索引列。优点： 把相关的数据保存在一起，比如实现电子邮箱时，根据用户ID来采集数据，只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件； 数据访问更快； 使用覆盖索引扫描的查询可以直接使用叶子页中的主键值。缺点： 插入速度严重依赖插入顺序； 更新聚簇索引代价高； 插入新行或更新主键导致行移动时可能会有“页分裂”（当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行）； 全表扫描变慢； 二级索引会很大，二级索引访问需要两次查找，一次找到二级索引的叶子节点获得主键值，一次根据主键值去聚簇索引中查找对应的行。6、覆盖索引：索引本身就包含所要查询字段的值。 当发起以被索引覆盖的查询，在EXPLAIN的Extra列可以看到“Using index”的信息。7、MyISAM的压缩索引方法：先完全保存索引块的第一个值，然后将其他值和第一个值进行比较得到相同前缀的字节数和剩余不同后缀部分，把字节数和后缀保存起来。这样后面的索引依赖前面的索引，没法对索引用二分查找，只能从头扫描。8、InnoDB在二级索引上使用共享锁，但访问主键索引需要排他锁。9、B-Tree索引可能会碎片化，降低查询效率；表数据存储也可能碎片化，​可以通过OPTIMIZE TABLE或者导出再导入的方式重新整理数据。​对于MyISAM可以通过排序算法重建索引消除碎片。 4、查询性能优化 1、重构查询1、 分解关联查询 让缓存效率更高； 执行单个查询减少锁的竞争； 在应用层做关联，更容易对数据库拆分，做到高性能和可扩展； 减少冗余记录的查找。2、查询执行的过程 1、客户端根据通信协议发送一条查询给服务器； 通信协议是半双工的，同一时刻只能一端发送； MySQL连接的状态 Sleep：线程在等待客户端发送新的请求； Query：线程正在执行查询或者正在将结果发送给客户端； Locked：服务器层线程在等待表锁； Analyzing and statistics：线程在收集存储引擎的统计信息，并生成查询的执行计划； Copying to tmp table [on disk]：线程正在执行查询，将结果集复制到一个临时表，三种可能：做GROUP BY、文件排序、UNION操作； Sorting result：线程在对结果集排序； Sending data：线程在多个状态之间传送数据，或着在生成结果集，或者在向客户端发送数据。2、服务器先检查查询缓存，如果命中缓存直接返回结果，否则进行下一阶段； 检查通过对大小写敏感的哈希查找实现。3、服务器进行SQL解析、预处理，再由优化器生成对应的执行计划； 执行计划是一种数据结构，是一棵指令树，左侧深度优先的树，而不是字节码； MySQL查询优化两种策略：静态和动态。区别：MySQL对静态优化只需要做一次，动态优化则在每次执行时都要重新评估。 MySQL执行关联查询：从一个表开始一直嵌套循环、回溯完成所有表的关联。4、MySQL根据执行计划调用存储引擎的API执行查询；5、返回结果给客户端。3、特定类型查询的优化 1、优化关联查询 确保任何GROUP BY和ORDER BY中的表达式只涉及到一个表中的列； 确保ON或USING子句上的列有索引。5、复制 1、复制概述1、MySQL支持两种复制方式：基于行的复制，基于语句的复制。两种方式都是通过在主库记录二进制日志、在备库上重放日志实现异步的数据复制。2、复制作用 负载均衡，可以将读操作分不到多个服务器上； 对备份的技术补充； 高可用性和故障切换； MySQL升级测试时查询能在备库按照预期执行。3、复制的流程 主库把数据更改记录到二进制日志中； 每次准备提交事务完成数据更新之前，MySQL按照事务提交的顺序记录二进制日志。 备库通过I/O线程与主库建立TCP/IP连接，将主库上的日志复制到自己的中继日志； 备库读取中继日志中的事件，将其重放到备库数据库上。2、复制的原理 1、基于语句的复制主句记录更改数据的查询，备库实际上就是把这些SQL语句再执行一遍。出现问题容易定位。2、基于行的复制直接将实际数据记录在二进制日志中。可以更高效的复制数据，但是二进制日志可能会很大，出现问题难定位。不必像基于语句的复制那样执行查询计划，会占用更少的CPU。 6、可扩展性1、负载均衡1、负载均衡算法 随机：随机从服务器池选择一台服务器处理请求； 轮询：以循环的顺序发送请求到服务器； 最少连接数：下一个连接请求发送给拥有最少活跃连接的服务器； 最快响应：能够最快处理请求的服务器接受下一个连接； 哈希：通过连接的源IP地址进行哈希，映射到同一个服务器上； 权重：性能好的服务器权重大，分配的请求更多。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的设计与实现]]></title>
    <url>%2F2019%2F06%2F15%2FRedis%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[1、数据结构与对象1、SDS简单动态字符串（Redis的默认字符串表示)1、redis需要一个可以被修改的字符串值时就会使用SDS表示字符串值。比如在Redis数据库里，包含字符串值的键值对在底层都是由SDS实现的。2、SDS还被用作缓冲区（buffer）：AOF模块中的AOF缓冲区，以及客户端状态的输入缓冲区。3、SDS遵循C字符串以空字符结尾的惯例，但是保存空字符的1字节空间不计算在SDS的len属性中，空字符对使用者来说时完全透明的，遵循这惯例的好处：SDS可以直接重用C字符串函数库里面的函数。 4、SDS和C字符串的区别： SDS常数时间复杂度获取字符串长度； C字符串底层实现是N+1长度的字符数组，要遍历字符串才能获得长度，SDS本身就记录了长度信息，确保获取字符串长度不会成为redis的瓶颈。 SDS可以杜绝缓冲区溢出 SDS的API在修改SDS之前会先检查空间是否足够，不够就会扩展。C中修改字符串如果不手动分配足够空间就可能出现把连续空间的其他内容修改或者时出现溢出。 SDS减少字符串修改带来的内存重新分配次数 对C字符串进行修改总要重新分配内存保存新的字符串。SDS中存储字符的buf字节数组如果空间不足也要重新分配，但是每次增加的空间不一定是修改字符所需的，会额外分配一些未使用空间，用free属性记录。SDS的两种优化策略：1、空间预分配字符长度len超过1M每次分配未使用空间也是1M，小于1M则每次分配与len相同的未使用空间。这样可以减少连续执行增加字符串操作所需的内存分配次数。2、惰性空间的释放SDS在缩短字符串的时候并不是立即通过重新分配内存来回收缩短的部分内存，而是将那部分内存当作未使用空间，供将来增长字符串使用，有专门的API用来释放这些内存，所以不担心内存浪费。 SDS二进制安全，可以保存文本数据或二进制数据 C字符串必须符合某种编码格式（如ASCII），且以空字符为结束标记，所以中间不能有空字符，所以C字符串只能保存文本数据，不能保存图片、视频等二进制文件。SDS的API都是二进制安全的，使用len的属性值判断字符串是否结束而不是空字符。 SDS兼容部分C字符串函数2、链表 1、特性 双向：每个节点都有前后两个指针； 无环：头节点的pre和尾节点的next都指向NULL； 带表头和表尾指针，获取表头结点和表尾节点时间复杂度是O(1)； 带链表长度计数器属性len，获取长度也是O(1)； 多态，链表节点使用void*指针来保存节点值，并且通过list结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。2、列表键的底层实现之一就是链表；发布与订阅、慢查询、监视器等功能也用到链表；redis服务器使用链表保存多个客户端的状态信息；使用链表来构建客户端输出缓冲区。3、字典 字典的底层使用哈希表实现，一个哈希表有多个哈希表节点，每个哈希表节点保存字典中的一个键值对。1、哈希表 哈希表数组table table保存指向dictEntry结构的指针，每个dictEntry结构保存一个键值对。 哈希表大小size 哈希表大小掩码sizemask，用于计算索引值，总等于size-1 哈希表已有的节点数量used2、哈希表节点dictEntry 键值对的值可以是一个指针，或者uint64_t整数，或者int64_t整数； next指针指向链表的下一个节点，因为这里用链地址法解决键的哈希冲突。3、字典 dictht ht[2]每一项都是一个dictht哈希表，ht[1]哈希表只在对ht[0]哈希表进行rehash时使用； rehashidx记录目前rehash的进度，-1代表没有进行rehash。4、哈希算法当新添加键值对到字典中，先用字典设置的哈希函数计算键的哈希值hash，然后使用哈希表的sizemask属性和哈希值计算索引 index=hash &amp; sizemask 5、Redis对字典的哈希表执行rehash 为ht[1]分配空间，执行扩展时空间大小为第一个大于等于ht[0].used*2的2^n；执行收缩时空间大小为第一个大于等于ht[0].used的2^n； 将ht[0]所有键值对rehash重新计算索引分配到ht[1]上； 将ht[1]设置为ht[0]，并在ht[1]上新建一个空白的哈希表。 6、哈希表的扩展与收缩满足以下任意条件则自动开始对哈希表进行扩展操作： 服务器目前没有执行BGSAVE或者BGREWRITEAOF，并且哈希表负载因子大于等于1； 服务器目前正在执行BGSAVE或者BGREWRITEAOF，并且哈希表负载因子大于等于5。 负载因子=哈希表已保存节点数 / 哈希表大小当哈希表负载因子小于0.1时自动执行收缩操作。7、渐进式的rehash 利用rehashidx记录ht[0]中已经rehash到ht[1]上的键值对索引值，分多次、渐进式的将ht[0]的键值对慢慢的rehash到ht[1]上，避免集中式的rehash带来的庞大计算量，对服务器性能造成影响。渐进式rehash期间，字典的删除、查找、更新会同时在两个表进行，新添加的只添加到ht[1]。8、应用在数据库和哈希键。 4、跳跃表（skiplist）1、跳跃表是一种有序数据结构，在每个节点维持多个指向其他节点的指针来实现快速访问其他节点的目的。支持平均O(logN)、最坏O(N)复杂度的节点查找，支持顺序性操作来批量处理节点。2、Redis只在两个地方应用跳跃表：实现有序集合键；在集群节点中用作内部数据结构。3、跳跃表中zskiplistNode用于表示跳跃表节点，zskiplist用于保存跳跃表节点的相关信息。 zskiplist：包括header表头节点、tail表尾节点、level记录目前跳跃表中层数最大的那个节点的层数、length跳跃表长度（不记头节点） zskiplistNopde: level层、后退指针、分值、成员对象。 level有两个属性：前进指针和跨度。前进指针用于从表头向表尾遍历，跨度是前进指针所指向节点和 当前节点的距离。层数量越多访问其他节点的速度越快。跳跃表按照节点分值从小到大排列。double类型的浮点数。分值相同的按照对象的字典顺序排列。成员对象是一个指针，指向一个字符串对象，该对象保存着一个SDS值。成员对象是唯一的。4、每个跳跃表节点的层高都是1-32之间的随机数。 5、整数集合（intset) 1、底层实现是一个数组，数组各个项从小到大有序排列，数组不包含重复项。2、添加新元素时，新元素的类型比现有元素数据类型都长的时候要先对整数集合升级（根据新元素类型扩容、现有元素转换类型、现有元素放置到合适的位置同时保证有序性、新元素添加到底层数组）。每次添加新元素是都有可能引发升级，添加新元素时间复杂度O(N)。 升级带来操作上灵活性，添加元素不用担心出现类型错误； 升级只在有需要的时候进行，可与尽量节约内存。3、整数集合不支持降级操作。6、压缩列表（ziplist) 压缩列表时列表键和哈希键的底层实现之一。1、压缩列表是Redis为节约内存开发的，是一系列特殊编码的连续内存块组成的顺序型数据结构。可包含任意多个节点，每个节点可以保存一个字节数组或一个整数值。2、压缩列表节点 previous__entry__length 记录i前一个节点的长度，通过这个指针可以实现压缩列表从表尾向表头遍历操作。 encoding：记录节点content的数据类型和长度 content3、连锁更新 在特殊情况下添加新节点或删除节点产生连续多次空间扩展操作。最坏情况下要对压缩列表执行N次空间重分配操作，每次空间重分配的最坏复杂度是O(N)，所以连锁更新的最坏复杂度是O(N^2)。出现几率低： 压缩列表里要恰好有多个连续的、长度介于250字节至253字节之间的节点，连锁更新才有可能发生。 即使出现连锁更新只要被更新的节点数量不多，不会对性能造成任何影响。8、对象 1、Redis使用对象来表示数据库中的键和值，创建一个键值对至少创建两个对象来分别作为键和值。2、Redis数据库保存的键值对，键总是字符串对象，值可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象其中一种。3、列表对象的编码可以是ziplist或者linkedlist；4、同时满足以下两个条件列表对象使用ziplist编码： 保存的所有字符串元素长度都小于64字节； 元素数量小于512个。以上两个条件的上限值可以修改。不能满足以上两个条件的需要使用linkedlist。5、哈希对象的编码可以是ziplist或者hashtable。 使用ziplist编码时，先将保存键的压缩列表节点推入表尾，再将保存了值的压缩列表节点推入表尾。键值对总是紧挨着，先添加的键值对在表头方向。6、集合对象的编码可以是intset或者hashtable。编码转换：当集合对象可以同时满足以下两个条件，对象使用intset编码 集合对象保存的所有元素都是整数值； 集合对象保存的元素数量不超过512个。以上条件中上限值可以在配置文件中修改。7、有序集合对象的编码可以时ziplist或者skiplist。 ziplist底层使用压缩列表实现，每个集合元素由两个紧挨着的压缩列表节点保存，第一个节点保存元素成员，第二个节点保存元素分值。元素按照分值从小到大排序。 skiplist编码的有序集合底层使用zset实现，一个zset结构同时包含一个字典和一个跳跃表，字典和跳跃表都通过指针共享相同元素的成员和分值，所以同时用这两种结构来保存集合元素不会产生重复元素和分值，也不会因此浪费内存。 为了让有序集合的查找和范围型操作尽可能快的执行，所以选择同时使用字典和跳跃表。字典可以在常数时间查找，跳跃表可以快速实现范围查找。因为有序集合键的值是哈希对象，所以用于有序集合的命令都是针对哈希对象构建的。8、特定类型命令在执行之前会通过redisObject结构的type属性进行类型检查。9、redis在对象系统中构建一个引用计数技术实现内存回收机制，程序通过引用计数跟踪对象的引用信息，在适当的时候自动释放对象并进行内存回收。对象的引用计数属性还带有对象共享的作用。共享对象只针对包含整数值的字符串对象。因为只有在共享对象和目标对象完全相同的情况下才能实现共享，这需要一个验证的过程，共享对象保存的值越复杂验证的复杂度越高，消耗的CPU时间越多。10、redisObject还有一个属性lru，记录了对象最后一次被命令程序访问的时间。空转时长是当前时间-lru时间。服务器如果设置了maxmemory并选择volatile-lru算法或者allkeys-lru算法用于内存回收，当到maxmemory上限值空转时长较高的键会优先被释放。 2、单机数据库的实现 1、数据库1、Redis服务器默认会创建16个数据库，保存在db数组中。2、客户端选择不同的数据库是使用SELECT命令，原理是通过修改redisClient.db指针，让它指向服务器中不同的数据库。3、设置过期时间 EXPIRE &lt;key&gt; &lt;ttl&gt;：将键key的生存时间设置为ttl秒； PEXPIRE &lt;key&gt; &lt;ttl&gt;：…设置为ttl毫秒； EXPIREAT &lt;key&gt; &lt;timestamp&gt;：将键key的过期时间设置为timestamp所指定的秒数时间戳； PEXPIREAT &lt;key&gt; &lt;timestamp&gt; : …设置为timest毫秒数时间戳。前三个命令最终都是使用PEXPIREAT命令实现的。4、TTL命令以秒为单位返回键的剩余生存时间，PTTL则是以毫秒为单位。 5、过期键删除策略 定时删除：设置键的过期时间同时创建一个定时器，让定时器在键的过期时间来临时立即执行对键的删除操作； 定时删除对内存最友好，但是对CPU时间是最不友好的，因此要让服务器创建大量定时器现阶段不现实。占用CPU时间多，影响服务器响应时间和吞吐量。 惰性删除：放任键过期不管，每次从键空间获取键时都检查取得的键是否过期，若过期就删除； 对CPU时间最友好，但是对内存最不友好。浪费内存，有内存泄漏的危险。 定期删除：每隔一段时间程序就对数据库进行一次检查，删除里面的过期键。 是以上两种的整合和折中。第一种第三种为主动删除，第二种是被动删除。 6、Redis的过期键删除策略：惰性删除和定期删除配合使用。 所有读写Redis数据库的命令在执行之前都会调用expireIfNeeded函数对输入键进行检查，如果过期则将输入键从数据库中删除； 定期删除通过activeExpireCycle函数进行：每次运行都从一定数量的数据库中取出一定数量的随机键进行检查，并删除其中的过期键；全局变量current_db记录当前函数的检查进度，以便下一次函数调用时接着上一次进度处理；最后服务器所有数据库都被检查一遍，_current_db重新置0。7、生成RDB文件时过期的键会被忽略，主服务器载入RDB文件时会对键进行检查只会载入未过期的键，从服务器则会将所有的键都载入数据库中，在主从同步的时候才会被清空。8、AOF重写中已过期的键会被检查出来，不会保存到重写的AOF文件中。9、服务器在复制模式下，从服务器的过期键删除由主服务器控制，只有当主服务器删除了过期键，然后给从服务器发送删除命令，从服务器才会删除过期键，这样来保证主从数据一致。 2、RDB持久化 1、RDB持久化生成的是一个经过压缩的二进制文件。两个命令可以生成RDB文件：SAVE和BGSAVE。 SAVE是由服务器进程执行保存工作，会阻塞服务器，拒绝客户端的所有命令请求 BGSAVE是派生一个子进程出来负责创建RDB文件，可以继续处理客户端的命令请求2、RDB文件的载入是在服务器启动时自动执行，载入期间服务器一直阻塞直到完成。3、服务器状态维持一个dirty计数器以及一个lastsave属性： dirty计数器记录距离上一次成功执行SAVE或BGSAVE命令之后服务器对数据库状态进行了多少次修改（写入、删除、更新等）； lastsave记录服务器上一次成功执行SAVE命令或BGSAVE命令的时间。4、间隔性数据保存的实现原理：Redis服务器根据save选项配置的条件，服务器的周期性操作函数serverCron默认每隔100毫秒执行一次，检查save选项设置的保存条件是否满足，满足就执行BGSAVE命令。5、RDB文件中有一个check_sum，程序载入文件后通过对REDIS、dbversion、databases、EOF_四部分计算出的校验与_check__sum比较，来检查RDB文件是否出错或者损坏。3、AOF持久化 1、AOF通过保存Redis服务器所执行的写命令来记录数据库状态，写命令以Redis的命令请求协议格式保存。2、AOF每执行完一个写命令就会以协议格式追加到服务器状态的aof_buf缓冲区末尾，这个命令是包含操作、key、value的。3、Redis服务器进程就是一个事件循环，服务器每结束一个事件循环之前，会调用flushAppendOnlyFile函数考虑是否需要把aof_buf缓冲区中的内容写入和保存到AOF文件中，主要是服务器配置appendfsync选项来决定不同的持久化行为： always：aof_buf所有内容写入并同步到AOF文件中，​效率最慢，安全性最高。 everysec：aof_buf的所有内容写入AOF文件，距离上次同步超过一秒钟就对AOF同步，同步由一个线程专门负责；​效率足够快，若出现故障停机只会丢失一秒钟的命令数据。 no：aof_buf的所有内容写入AOF中，但同步由操作系统决定。​写入速度最快但是同步时间最长，而且会在系统缓存中积累一段时间的写入数据，若故障停机会丢失上次同步AOF文件之后的所有写命令数据。 ​4、AOF文件的载入与数据还原 创建一个不带网络连接的伪客户端，因为redis命令只能在客户端上下文中执行，载入AOF文件的命令直接来源AOF文件而不是网络连接； 从AOF文件分析并读取一条写命令； 使用伪客户端执行被读出的命令； 一直执行2、3直到AOF文件中所有写命令都被处理完毕。5、AOF文件重写 Redis服务器创建一个新的AOF文件代替旧的AOF文件，两个文件保存的数据库状态相同，新的AOF文件中包含的命令更少，所以体积会更小。 实现原理：首先从数据库读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。重写会忽略空数据库和过期键。 为了避免在执行命令时造成客户端输入缓冲区的溢出，重写在处理列表、哈希表、集合、有序集合这四种会带有多个元素的键时，会先检查元素数量是否超过redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD常量值，如果超过会用多条命令记录这个集合。 AOF后台重写（BGREWRITEAOF命令）实现原理：AOF后台启动子进程来重写AOF，为了解决父子进程数据不一致的问题，Redis服务器设置了一个AOF重写缓冲区，在子进程重写期间，服务器进程每执行一个写命令都要将其追加到AOF重写缓冲区，子进程完成重写之后向父进程发送信号，父进程收到后就调用一个信号处理函数：将AOF重写缓冲区中的所有内容写入新的AOF文件中，对新AOF文件改名并原子地覆盖现有的AOF文件。调用信号处理函数父进程会阻塞。4、事件 1、文件事件文件事件处理器是基于Reactor模式开发的网络事件处理器： 使用I/O多路复用程序同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器； 当被监听的套接字准备好执行连接应答、读取、写入、关闭等操作时，与操作相对应的文件事件就会产生，文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。文件事件处理器以单线程方式运行，方便与服务器其他模块对接，保持了Redis内部单线程设计的简单性。使用I/O多路复用实现高性能。 文件事件可能会并发出现，I/O多路复用程序会将所有产生事件的套接字放到一个队列中，以此保证有序、同步的每次向文件事件分派器发送一个套接字，处理完一个套接字队列才会继续发送下一个。 文件事件的处理器：连接应答处理器、命令请求处理器、命令回复处理器、复制处理器（主从复制时用到）一次客户端与服务器连接事件实例： 客户端发送连接请求，服务器执行连接应答处理器； 客户端发送命令请求，服务器执行命令请求处理器； 服务器向客户端发送命令回复，服务器执行命令回复处理器。2、时间事件 主要有定时事件和周期事件。服务器会为时间事件创建全局唯一ID，id从小到大递增；服务器将所有时间事件放在一个无序链表中，当时间事件执行器运行时就遍历整个链表，查找所有已到达的时间事件，并调用相应的事件处理器。 新的事件总是插入到链表头部，所以链表中事件时有按照ID排序的，无序指的是不按照时间排序。目前版本，服务器最多只是用两个时间事件，所以无序链表几乎退化成一个指针使用，所以不会影响事件执行的性能。3、事件的调度和执行 事件的处理都是同步、有序、原子地执行，服务器不会中途中断，也不会对事件进行抢占； 因为时间事件在文件事件之后执行，并且事件之间不会抢占，所以时间事件的实际处理时间通常会比时间事件预定的到达时间稍晚一点。 5、客户端1、Redis服务器是一对多服务器程序，通过I/O多路复用技术实现的文件事件处理器来保证服务器使用单线程单进程处理多个客户端的命令请求。2、服务器状态结构使用clients链表连接起多个客户端状态，新添加的客户端被放到链表末尾。 6、服务器1、serverCron函数默认每隔100毫秒执行一次，主要：更新服务器状态信息、处理服务器接收的SIGTERM信号、管理客户端资源和数据库状态、检查并执行持久化操作。2、服务器启动到能够处理请求需要先执行：初始化服务器状态、载入服务器配置、初始化服务器数据结构、还原数据库状态、执行事件循环。 3、多机数据库的实现1、复制1、旧版复制分同步和命令传播两个操作2、同步是从服务器向主服务器发送SYNC命令完成： 从服务器向主服务器发哦是那个SYNC命令； 主服务器收到命令后执行BGSAVE命令，后台生成一个RDB文件，并使用一个缓冲区记录从现在开始执行的所有写命令； 主服务器的BGSAVE命令执行完毕后，将RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令时的状态； 主服务器将记录在缓冲区的所有写命令发送给从服务器，从服务器执行这些写命令，保证了主从服务器的数据一致。3、命令传播：主服务器会将自己执行的写命令发送给从服务器执行，保证主从一致。 旧版复制中如果在命令传播过程从服务器断开连接了，自动重连接之后会发送SYNC命令执行主从同步，效率低下。4、新版复制使用PSYNC命令代替SYNC命令执行同步操作，PSYNC命令具有完整重同步和部分重同步： 完整重同步用于处理初次复制，和SYNC命令步骤一样； 部分重同步用于断线后重复制情况：主服务器会将连接断开期间执行的写命令发送给从服务器，从服务器接收并执行这些写命令。5、部分重同步的实现： 主从服务器分别维护一个复制偏移量，主服务器每发送N字节偏移量就加N，从服务器收到N字节偏移量就加N； 主服务器维护一个固定长度的先进先出队列，也就是复制积压缓冲区，里面保存一部分最近传播的写命令，并且队列中每个字节都记录了相应的复制偏移量，从服务器断线后重连会向主服务器发送PSYNC命令把自己的偏移量通知给主服务器，主服务器判断该偏移量是否还存在缓冲区，如果存在执行部分同步，否则执行完整重同步。缓冲区大小默认1MB，应该根据需要修改。 每个Redis服务器都有自己的运行ID，主服务器在第一次复制的时候把自己的ID发送给从服务器，后续的同步中从服务器发送这个ID给主服务器，主服务器判断这个ID是不是自己，如果是可以尝试执行部分重同步，不是则执行完整重同步。6、PSYNC命令的实现 从服务器如果是首次复制，会向主服务器发送PSYNC ？ -1命令请求一次完全复制； 非首次复制时，从服务器向主服务器发送PSYNC &lt;runid&gt; &lt;offset&gt;命令，其中runid是上一次同步的主服务器ID，offset则是上一次复制偏移量，主服务器根据这两个参数判断应该执行完全复制还是部分复制。7、从服务器成为主服务器的客户端之后第一件事就是发送PING命令给主服务器，有以下作用： 检查主从服务器建立的套接字链接读写状态是否正常； 检查主服务器是否能正常处理命令请求。8、心跳检测：从服务器默认每秒一次的频率向主服务器发送命令 REPLCONF ACK &lt;replication_offset&gt; 其中offset是当前从服务器的复制偏移量。主要作用： 检测主从服务器的网络连接状态 辅助实现min-slaves选项 检测命令丢失：通过偏移量可以发现2、哨兵（Sentinel） 1、哨兵是Redis高可用性的解决方案：由一个或多个Sentinel实例组成的Sentinel系统可以监视任意多个主服务器以及这些主服务器下属的所有从服务器，并在被监视的主服务器下线后自动将其下属的某个从服务器升级为新的主服务器，原来的主服务器上线后会被设置为新主服务器的从服务器。2、初始化Sentinel关键步骤： 初始化Sentinel状态中的masters字典，里面记录所有被Sentinel监视的主服务器的信息； 创建连接主服务器的网络连接，因为需要与多实例创建连接所以使用异步连接。 会创建两个异步网络连接：一个命令连接专门用于向主服务器发送命令并接收命令回复；一个是订阅连接专门用于订阅主服务器的snetinel_:hello频道。创建两个连接是因为：Redis目前的发布与订阅功能中，被发送的消息都不会被保存在Redis服务器里，如果消息发送时接收信息的客户端不在线或者断线，那这个客户端就会丢失这条信息，为了不丢失信息，sentinel专门用一个订阅连接来接收信息。发送命令需要创建命令连接。_3、sentinel默认每10秒通过命令连接向被监视的主服务器发送INFO命令，通过分析命令的回复获取主服务器当前信息。4、sentinel发现主服务器有新的从服务器出现，会为其创建相应的实例结构，还创建到从服务器的命令连接和订阅连接。5、监视同一个主服务器的sentinel还会建立起命令连接，相互进行信息交换。6、在配置的连续时间内主服务器都向监视的sentinel发送无效回复，则sentinel判定该服务器主观下线，然后sentinel向其他也监视了这台服务器的sentinel发送命令，看其他sentinel是否也认为这台服务器主观下线，如果得到一定数量的回复则sentinel会判定该服务器客观下线，监视这个主服务器的sentinel会协商选一个领头的sentinel，由领头sentinel对下线主服务器执行故障转移操作。 3、集群 1、集群式Redis提供的分布式数据库方案，集群通过分片（sharding）来进行数据共享，并提供复制和故障转移功能。2、两个节点通过CLUSTER MEET命令实现握手，加入同一个集群中，握手过程： 客户端发送命令 CLUSTER MEET &lt;B__ip&gt; &lt;B_port&gt; _给节点A，A为节点B创建一个clusterNode结构，然后给B发送MEET消息； B收到MEET消息后，为A创建一个clusterNode结构，并向A返回一个PONG消息，表示收到A的MEET消息了； A收到B的PONG消息后将向B发送一条PING消息，表示收到B的PONG消息，两边都确认收到对方消息，这样握手完成。A会将B的信息通过Gossip协议传播给集群的其他节点，让其他节点也与节点B进行握手。3、集群通过分片的方式保存数据库中的键值对：集群整个数据库被分为16384个槽（slot），数据库中每个键都属于这16384个槽的其中一个，集群中每个节点可以处理0个或最多16384个槽。4、槽指派信息不仅保存在各个节点的clusterNode.slots数组中，还保存在clusterState.slots数组中。 如果仅保存在clusterNode.slots数组中，为了直到槽 i是否已经被指派或被指派给哪个节点，程序需要遍历clusterState.nodes字典中所有的clusterNode结构，检查这些结构的slots数组，复杂度O(N)；保存在clusterState.slots中只需要访问slots[i]即可，复杂度O(1)。保存在clusterNode.slots数组的好处：当程序需要把某个节点的槽指派信息发送个其他节点时直接发送这个数组就可以了，如果单独使用clusterState.slots数组的话，每次都得遍历数组才能知道节点的槽指派信息，比直接发送clusterNode.slots数组麻烦低效。5、节点和单机服务器在数据库方面的区别时节点只能使用0号数据库，而单机Redis服务器没有限制。6、集群中节点分为主节点和从节点，主节点用于处理槽，从节点复制某个主节点并在主节点下线时代替主节点继续处理命令请求。7、集群节点之间通过消息来通信。 4、独立功能实现 1、事务1、Redis通过MULTI、EXEC、WATCH等命令来实现事务，事务是将多个命令请求打包，然后一次性、顺序地执行多个命令请求的机制，并且事务执行期间服务器不会中断事务而去执行其他客户端的命令请求，会把事务中所有命令执行完毕才去处理其他客户端的请求。2、事务队列是一个multiCmd类型数组，先入队的命令放在数组前面，保证先进先出。3、WATCH命令是一个乐观锁，在执行事务的命令EXEC执行之前监视任意数量的数据库键，在EXEC执行时检查被监视的键是否至少有一个已经被修改过了，如果是Redis客户端的REDIS__DIRTY__CAS标识被打开，服务器根据标志位是否被打开决定是否拒绝执行事务。Redis数据库保存了一个字典，键是某个被WATCH命令监视的数据库键，值是一个链表，链表元素是所有监视相应数据库键的客户端。4、事务的ACID 原子性：事务队列的命令要么全部执行要么一个都不执行。但是Redis事务不支持回滚，中间某个命令执行错误后续的命令也会被执行，不支持事务回滚时因为Redis追求简单高效，Redis事务执行错误通常是编程错误产生，出现在开发环境中，很少在实际生产环境中出现。 一致性：通过错误检测和持久化保证。 隔离性：Redis事务总是以串行方式运行，并且服务器保证在执行事务期间不会对事务进行中断。 耐久性：当服务器运行在AOF持久化模式下，并且appendfsync选项值为always时，事务才具有耐久性。2、慢查询 1、两个参数：slowlog-log-slower-than和slowlog-max-len，第一个参数指定执行时间超过多少微秒的命令记录到日志上；第二个参数执行服务器最多保存多少条慢查询日志。2、到达最大限制数量时，会把最旧的慢查询删除，再保存新的。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Redis的设计与实现</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList]]></title>
    <url>%2F2019%2F06%2F10%2FArrayList%2F</url>
    <content type="text"><![CDATA[1、继承了AbstractList类，实现了List接口、RandomAccess接口。 RandomAccess接口是一个标识，实现这个接口的数据结构支持随机访问，因为ArrayList底层是数组实现，天然支持随机访问，所以标识。 2、1.8的注释提到：与Vector几乎相同，除了不是同步的，即ArrayList不是线程安全的，线程安全的情况需要用Vector或者CopyOnWriteArrayList。 3、fail-fast：是Java集合的一种错误检测机制，当利用迭代器遍历集合元素的时候，创建迭代器之后就不能对集合元素修改（删除、增加），否则就抛出 ConcurrentModificationException ，但是可以通过调用迭代器本身提供的方法进行增加删除元素。 产生原因：在创建Iterator时就定义了一个变量迭代器在调用 next()、remove() 方法时都是调用 checkForComodification() 方法，该方法主要就是检测 modCount == expectedModCount ? 若不等则抛出 ConcurrentModificationException 异常，从而产生 fail-fast 机制。ArrayList 中无论 add、remove、clear 方法只要是涉及了改变 ArrayList 元素的个数的方法都会导致 modCount 的改变。 4、默认设置 12345678//默认初始化大小private static final int DEFAULT_CAPACITY = 10;//有参构造时调用，即指定初始化大小private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//空参构造调用，当空数组第一个元素被添加的时候，数组大小才扩大到10private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;//数组最大容量，因为需要8 bytes存储数组大小，所以-8。最大2^31，所以要8 bytes.private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 5、扩容具体实现：新建一个大小是原来1.5倍的数组，把原来数组的元素复制过去。 1234567891011121314151617181920private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 移位运算效率更高 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; //比较所需要的数组容量大小minCapacity和数组最大容量的大小关系private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; Arrays.copyOf 是内部新建一个数组，然后把传入的数组元素拷贝到新数组，返回新数组。 6、remove方法是把元素往前移，然后把末尾的位置指向null，clear方法是把所有位置指向null，然后交给垃圾回收机制处理。]]></content>
      <categories>
        <category>源码学习</category>
      </categories>
      <tags>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadPoolExecutor]]></title>
    <url>%2F2019%2F06%2F08%2FThreadPoolExecutor%2F</url>
    <content type="text"><![CDATA[1、继承关系ThreadPoolExecutor继承于AbstractExecutorService--&gt;ExecutorService--&gt;Executor 2、线程池状态1、用一个int类型表示，共32位，前三位表示线程池状态，后29位表示线程数量，线程池的状态有： RUNNING：接受新任务并且处理阻塞队列里的任务 SHUTDOWN：拒绝新任务但是处理阻塞队列里的任务 STOP：拒绝新任务并且抛弃阻塞队列里的任务同时会中断正在处理的任务 TIDYING：所有任务都执行完（包含阻塞队列里面任务）当前线程池活动线程为0，将要调用terminated方法 TERMINATED：终止状态。terminated方法调用完成以后的状态 2、各种状态之间的转换 RUNNING -&gt; SHUTDOWN显式调用shutdown()方法，或者隐式调用了finalize(),它里面调用了shutdown（）方法。 RUNNING or SHUTDOWN)-&gt; STOP显式 shutdownNow()方法 SHUTDOWN -&gt; TIDYING当线程池和任务队列都为空的时候 STOP -&gt; TIDYING当线程池为空的时候 TIDYING -&gt; TERMINATED当 terminated() hook 方法执行完成时候 3、构造函数有四个构造函数，其他三个都是调用以下这个： 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize：线程池核心线程个数 workQueue：用于保存等待执行的任务的阻塞队列 maximunPoolSize：线程池最大线程数量 keepAliveTime：线程的存活时间。当线程池里的线程数大于corePoolSize时，如果等了keepAliveTime时长还没有任务可执行，则线程退出 ThreadFactory：创建线程的工厂，主要是为了给线程起名字，默认工厂的线程名字：pool-1-thread-3 TimeUnit：存活时间的时间单位 RejectedExecutionHandler：饱和策略，当队列满了并且线程个数达到maximunPoolSize后采取的策略 AbortPolicy：直接抛出 RejectedExecutionException 异常； CallerRunsPolicy：使用调用者所在线程来运行任务； DiscardOldestPolicy：调用poll丢弃队列里面最老的（队尾）任务，执行当前任务； DiscardPolicy：默默丢弃,不抛出异常。 4、执行过程1、如果当前线程池线程个数小于corePoolSize则调用addWorker开启新线程；否则添加任务到任务队列；如果任务队列满了，则尝试调用addWorker新开启线程执行任务，如果线程个数&gt;maximumPoolSize则执行拒绝策略。 2、addWorker方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 检查队列是否只在必要时为空.（1） if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; //循环cas增加线程个数 for (;;) &#123; int wc = workerCountOf(c); //如果线程个数超限则返回false if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //cas增加线程个数，同时只有一个线程成功 if (compareAndIncrementWorkerCount(c)) break retry; //cas失败了，则看线程池状态是否变化了，变化则跳到外层循环重试重新获取线程池状态，否者内层循环重新cas。 c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; &#125; &#125; //到这里说明cas成功了，（2） boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; //创建worker final ReentrantLock mainLock = this.mainLock; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; //加独占锁，为了workers同步，因为可能多个线程调用了线程池的execute方法。 mainLock.lock(); try &#123; //重新检查线程池状态，为了避免在获取锁前调用了shutdown接口(3) int c = ctl.get(); int rs = runStateOf(c); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); //添加任务 workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; //添加成功则启动任务 if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 3、工作线程Worker的执行 12345Worker(Runnable firstTask) &#123; setState(-1); // 在调用runWorker前禁止中断 this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this);//创建一个线程&#125; 4、调用shutdown后，线程池就不会在接受新的任务了，但是工作队列里面的任务还是要执行的，但是该方法立刻返回的，并不等待队列任务完成在返回。调用awaitTermination完成队列里面的任务的处理 5、通过线程池状态来控制任务的执行，每个worker线程可以处理多个任务，线程池通过线程的复用减少了线程创建和销毁的开销，通过使用任务队列避免了线程的阻塞从而避免了线程调度和线程上下文切换的开销。 部分来源：http://ifeve.com/java%E4%B8%AD%E7%BA%BF%E7%A8%8B%E6%B1%A0threadpoolexecutor%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/]]></content>
      <categories>
        <category>源码学习</category>
      </categories>
      <tags>
        <tag>JUC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP与UDP的比较]]></title>
    <url>%2F2019%2F04%2F15%2FTCP%E4%B8%8EUDP%2F</url>
    <content type="text"><![CDATA[1、UDP和TCP区别1、UDP（用户数据报协议）是无连接的，不可靠的，尽可能大量的发送数据包，没有流量控制、拥塞避免、丢包不重传，无序 UDP因为无连接，随时可以向对端发送数据包，且本身处理简单高效，常用于：数据包总量较少的通信（DNS、SNMP）；视频、音频等对实时性要求高的多媒体通信；广播通信、多播通信2、TCP面向连接的，双方必须先创建连接才能发送数据，而且有一系列的方式保证传输可靠，有序 来源：https://www.cnblogs.com/steven520213/p/8005258.html 2、TCP如何保证可靠性TCP通过序列号、校验和、确认应答型号、重发控制、连接管理、窗口控制、流量控制、拥塞控制实现可靠性。（三次握手、四次挥手、流量控制、拥塞避免）1、TCP是位于传输层的协议，面向连接，提供可靠传输，有流量控制、拥塞控制，是一对一的传输 三次握手1、客户端先发送一个SYN给服务端，请求连接；2、服务端回复ACK确认连接，同时也发送SYN给客户端；3、客户端回复ACK给服务端确认连接，这样双方通过相互请求和相互确认就可以建立连接。 四次挥手1、客户端发送FIN报文给服务端，请求断开连接；2、服务端收到客户端的FIN之后，发出ACK确认，此时TCP处于半连接状态，如果服务端数据还没发送完毕可以继续向客户端发送，客户端只能接收不能发送；3、当服务端数据发送完毕之后向客户端发送FIN报文，通知客户端数据已经发送完毕可以完全关闭连接4、客户端回复ACK给服务端确认关闭连接 可靠传输超时重传 流量控制滑动窗口 拥塞控制四种方式：慢开始，拥塞避免，快重传，快恢复需要维护一个拥塞窗口cwnd的状态量 慢开始与拥塞避免 一开始令cwnd=1，发送方只发送一个报文，收到确认后，cwnd加倍；为了避免网络拥塞，需要给cwnd设定一个限定值ssthresh，超过限定值之后每次只增加1个，也就是进入拥塞避免。如果出现超时，ssthresh=cwnd/2，重新执行慢开始 快重传与快恢复 接收方收到的每一个报文需要对每一个报文发送确认，如果发送方连续收到三个相同的确认，则立即重传下一个报文；在这种丢失个别报文的情况下，执行快恢复，令ssthresh=cwnd/2，cwnd=ssthresh，此时是直接进入拥塞避免 来源：https://blog.csdn.net/cmm0401/article/details/77878998 3、为什么要三次握手四次挥手？三次握手是为了建立可靠连接，防止已经失效的连接请求突然到达造成错误。四次挥手是为了保证完成数据传输。 4、为什么状态还需要等2MSL后才能返回到CLOSED状态？1、MSL是指报文在网络上最长存活时间，这是因为虽然双方都同意关闭连接了，而且握手的4个报文也都协调和发送完毕，按理可以直接回到CLOSED状态（就好比从状态到状态那样）；但是因为我们必须要假想网络是不可靠的，你无法保证你最后发送的ACK报文会一定被对方收到，因此对方处于状态下的可能会因为超时未收到报文，而重发报文，所以这个状态的作用就是用来重发可能丢失的报文。2、关闭这个链接，过一段时间后在 相同的IP地址和端口建立另一个连接。后一个链接成为前一个的化身。因为它们的IP地址和端口号都相同。TCP必须防止来自某一个连接的老的重复分组在连 接已经终止后再现，从而被误解成属于同一链接的某一个某一个新的化身。为做到这一点，TCP将不给处于TIME_WAIT状态的链接发起新的化身。既然 TIME_WAIT状态的持续时间是MSL的2倍，这就足以让某个方向上的分组最多存活msl秒即被丢弃，另一个方向上的应答最多存活msl秒也被丢弃。 通过实施这个规则，我们就能保证每成功建立一个TCP连接时。来自该链接先前化身的重复分组都已经在网络中消逝了。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器上给定URL的具体访问过程]]></title>
    <url>%2F2018%2F11%2F08%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E4%B8%8A%E7%BB%99%E5%AE%9AURL%E7%9A%84%E5%85%B7%E4%BD%93%E8%AE%BF%E9%97%AE%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1、Http协议基于应用层的一个规范标准，通信双方都要遵守 2、一次Http请求的完整过程1、浏览器输入一个地址，首先要进行域名解析，浏览器先去系统的host文件查找有没有域名对应的IP，如果没有再去本地DNS服务器（由运营商提供）查询是否有对应的IP地址；2、本地DNS服务器如果没有，需要到根域服务器查询，查询方式有两种： 迭代查询 当遇到自己服务器不能回答的DNS查询请求时，把能解析该域名的服务器地址返回给客户端DNS程序，最终客户端只和一台服务器进行了域名/IP信息的传送 递归查询 当遇到自己服务器不能回答的DNS查询请求时，它会逐级往下向其他DNS服务器进行查询，最后所有参与此次查询IP的服务器都会得到该域名和对应IP信息 3、经过DNS服务器解析之后客户端得到域名的IP地址，首先发起TCP连接请求（三次握手）；4、建立起TCP连接之后，客户端发起Http请求；5、连接建立之后服务端进行响应，客户端接收响应并展示给用户；6、浏览器得到HTML代码，会进行解析，这个过程中可能还会不断通过Ajax向服务端发起异步加载的请求，最终将页面完整展示 3、GET和POST请求的区别1、GET请求中的参数包含在URL中，数据可以在URL中看到，而POST请求的URL不会包含这些数据，数据都是通过表单形式传输，会包含在请求体中；２、GET请求提交的数据最多只有1024字节，而POST方式没有限制。 需要提交用户密码和用户名，其中包含敏感信息，使用GET请求的话密码就会暴露在URL中，所以应该选POST。上传文件内容比较大，也应该选POST。 4、Http协议的无状态1、无状态是指Http协议对事务的处理没有记忆能力，服务器不知道客户端是什么状态2、保持状态的两种技术：session和cookie。session保存在服务端，cookie保存在客户端3、浏览器关闭cookie消失，但是session是服务器端的，不会被删除。 5、Https协议 = Http协议 + SSL（安全套接字）1、https减低用户访问速度，因为多了很多次握手2、安全 所有信息都是加密的 有校验机制，一旦篡改通信双方都会发现； 配备身份证书，防止身份被冒充]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>JavaWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM知识点总结]]></title>
    <url>%2F2018%2F10%2F12%2FJVM%2F</url>
    <content type="text"><![CDATA[1、内存区域1、堆内存 所有的对象实例都存放在堆内存，所有线程共享的堆内存 Java堆自动化管理，通过垃圾回收机制自动清理垃圾对象 分为新生代（Eden、s0、s1）和老年代 2、栈 线程私有的内存空间（三部分：局部变量表、操作数栈、帧数据区） 随着线程的结束而结束 3、方法区 线程共享，保存已经被加载的类信息、方法、常量池、静态变量、即时编译器编译后的代码数据。 可以理解为永久区 这部分的内存回收主要是针对常量池的回收和对类型的卸载 4、CAS（Compare And Swap） 1234执行函数：CAS（V,E,N） V表示需要读写的内存位置 E表示进行比较的预期原值 N表示打算写入的新值 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置的值更新为新值，否则不做任何操作。CAS操作是原子的。 5、如果是建立过多线程导致的内存溢出，在不能减少线程数或者更换64位虚拟机的情况下，只能通过减少最大堆和减少栈容量来换取更多的线程。2、垃圾回收1、对象是否存活（判断一个对象是否可回收的方法） 引用计数法 给对象添加一个计数器，有引用值加1，引用失效值减1，当计数器值为0时，该对象不能再被使用缺点：存在对象之间相互循环引用的问题导致对象无法被回收，占用资源 可达性分析算法 通过“GC Roots”对象为起始点，当一个对象到GC Roots没有任何引用链相连，则该对象不可用，将会被回收。 2、引用 强引用 类似” Object obj = new Object()“这类声明对象引用，只要对象存在强引用就不会被回收 软引用 做缓存用，有用并非必需的对象。在内存溢出之前会被回收以空出内存 弱引用 做缓存用，非必需的对象。只能生存到下一次垃圾回收发生之前 虚引用 唯一目的就是在这个对象在被回收时收到一个系统通知 3、垃圾回收算法 标记-清除算法 标记需要被回收的对象---&gt;标记完成后统一回收标记和清除效率都不高；会产生大量不连续的内存碎片 复制算法 内存分两块，一次使用一块，清理的时候将存活的对象复制到另一块内存上，然后全部清理一般分成较大的Eden空间和两块较小的Survivor空间，一次只使用Eden和一块Survivor，当另一块Survivor无法存放上一次新生代收集的存活对象则这些对象会通过分配担保机制进入老年代。对象到达一定的年龄也会自动进入老年代，对象年龄由GC次数决定 标记-整理算法 标记需要回收的对象，然后让所有存活的对象向一端移动，清理端边界外的内存新生代使用复制算法，老年代使用标记-整理算法 4、垃圾收集器 Serial收集器 单线程，垃圾收集的时候必须暂停其他所有线程的运行优点：简单高效。 新生代收集器 ParNew收集器 Serial的多线程版本新生代收集器 Parallel Scavenge收集器 新生代收集器，使用复制算法，并行多线程目标是达到设定的吞吐量目标，吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间） Serial Old收集器 Serial的老年代版本，使用标记-整理算法 Parallel Old收集器 Parallel Scavenge的老年代版本，使用多线程和标记-整理算法在注重吞吐量和CPU资源敏感的场合，可以优先考虑Parallel Scavenge和Parallel Old的组合 CMS（Concurrent Mark Sweep）收集器 获取最短回收停顿时间，基于标记-清除算法优点：并发收集、低停顿缺点： 对CPU资源非常敏感 无法处理浮动垃圾，可能出现Concurrent Mode Failure​而导致另一次Full GC的产生 标记-清除算法产生大量空间碎片，容易导致没有足够空间来分配给大对象，这样就会提前触发一次Full GC G1收集器 面向服务端应用的垃圾收集器优点： 并行与并发：利用多核多CPU缩短停顿时间 空间整合：整体使用标记-整理算法，局部使用复制算法，收集垃圾后能提供规整的可用内存 分代收集：将堆分成一块块的区域，新生代和老年代不再是物理上隔离的 可预测的停顿 5、内存分配与回收 对象优先在新生代Eden区分配 当Eden区空间不够时，虚拟机会发起一次Minor GC（发生在新生代的GC，比较频繁，回收速度也快） 大对象直接进入老年代 大对象就是需要大量连续内存的对象 长期存活的对象进入老年代 动态对象年龄判定 如果Survivor空间中相同年龄的所有对象占有空间超过Survivor的一半，则大于等于该年龄的对象直接进入老年代 空间分配担保 JDK6之后的规则：只要老年代的连续内存空间大于新生代对象的总大小或历次晋升的平均大小就会进行Minor GC，否则进行Full GC 3、JDK工具 jps（JVM Process Status Tool）虚拟机进程状况工具 列出正在运行的虚拟机进程，显示虚拟机执行主类名称，以及这些进程的本地虚拟机唯一ID（LVMID） jstat（JVM Statistics Monitoring Tool）虚拟机统计信息监视工具 可以显示本地或远程虚拟机进程的类加载、内存、垃圾收集、JIT编译等运行数据 jinfo（Configuration Info for Java ）Java配置信息工具 实时查看和调整虚拟机各项参数 jmap（Memory Map for Java）内存映像工具 主要用于生成堆转储快照 jstack（Stack Trace for Java）堆栈跟踪工具 用于生成虚拟机当前时刻的线程快照线程快照：当前虚拟机每一条线程正在执行的方法堆栈的集合 4、类加载 1、Class类文件Class文件是一组以八位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑排列 2、类加载的生命周期从类被加载到虚拟内存到卸载出内存为止，整个生命周期：加载--&gt;验证--&gt;准备--&gt;解析--&gt;初始化--&gt;使用--&gt;卸载 1、对一个类的主动引用会触发初始化（在之前加载、验证、准备需要开始），有且只有以下五种情况： 遇到 new、getstatic、putstatic、invokestatic这四条字节码指令时 使用java.lang.reflect包的方法对类进行反射调用时 初始化一个类时，如果其父类还没初始化则要先初始化父类 虚拟机启动时要指定一个要执行的主类（包含main方法的类），虚拟机先初始化这个类 使用JDK1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄对应的类没有初始化，则需要先对这个类初始化其他都称为被动引用，不会触发初始化。被动引用的例子： 通过子类引用父类的静态字段，不会导致子类的初始化 通过数组定义来引用类，不会触发此类的初始化 123456789101112131415public class SuperClass()&#123; static &#123; System.out.println(&quot;SuperClass init&quot;); &#125; public static int value = 123;&#125;public class SubClass extends SuperClass &#123; static&#123; System.out.println(&quot;SubClass init&quot;); &#125;&#125;//引用静态字段SubClass.value;//数组定义引用SuperClass[] sca = new SuperClass[10]; 常量在编译阶段会存入调入类的常量池中，本质上没有直接引用定义常量的类，因此不会触发定义常量的类初始化接口的初始化与类的初始化的区别是五种有且仅有​前三种：父接口只有在使用到的时候才会初始化 2、类加载 1、验证 文件格式验证 基于二进制字节流进行 元数据验证 字节码验证 符号引用验证 2、准备正式为类变量分配内存并设置初始值，这里的类变量是指被static修饰的变量，内存分配不包括实例变量；初始值一般是数据类型的零值，特殊情况比如被final修饰，则会直接赋值。3、类和加载它的类加载器确定了其在Java虚拟机中的唯一性。比较两个类是否“相等”，只有在这两个类都由同一个类加载器加载的前提下才有意义。4、双亲委派模型 启动类加载器 扩展类加载器 应用程序类加载器 自定义类加载器如果一个类加载器收到类加载的请求，首先不会自己去加载，而是委派给父类加载器去加载，每一层加载器都是如此，因此最后所有的类加载请求都会传送到顶层的启动类加载器，只有父类加载器反馈说自己无法加载，子类加载器才会自己尝试加载。 好处：* ​Java类随着类加载器一起具有了层级优先关系，能够有效确保一个类的全局唯一性。如java.lang.object类，由启动类加载器加载，这样object不管在哪个类加载器环境下都是同一个类。*5、虚拟机字节码执行引擎 1、栈帧结构栈帧是用于支持虚拟机方法调用和方法执行的数据结构，是虚拟机运行时数据区的虚拟机栈的栈元素，存储着方法的局部变量表、操作数栈、动态连接和方法返回地址等。 局部变量表 容量的最小单位是槽（slot），一个slot能够存放一个32位以内的数据类型64位的数据类型虚拟机会以高位对齐的方式分配连续的两个slot空间slot可以重用 操作数栈 栈元素可以是任何的Java数据类型，32位占容量1，64位占容量2 方法返回地址方法退出等同把当前栈帧出栈，可能的操作有：恢复上层方法的局部变量表和操作数栈，把返回值（如果有）压入调用者栈帧的操作数栈，调整PC计数器的值以指向方法调用指令后的一条指令2、方法调用 方法调用不是方法执行，该阶段唯一任务就是确定被调用方法的版本（调用哪个方法） 解析调用 主要是四类方法的调用：静态方法、私有方法、实例构造器、父类方法解析调用是一个静态过程，在编译期就完全确定，在类加载的解析阶段就会把涉及到的符号引用转化为可确定的直接引用。 分派 静态分派（典型应用：重载） 1234567891011121314151617181920212223242526 public class StaticDispatch &#123; static abstract class Human&#123;&#125; static class Man extends Human&#123;&#125; static class Woman extends Human&#123;&#125; public void SayHello(Human guy)&#123; System.out.println(&quot;Hello guy&quot;); &#125; public void SayHello(Man man)&#123; System.out.println(&quot;Hello gentleman&quot;); &#125; public void SayHello(Woman woman)&#123; System.out.println(&quot;Hello lady&quot;); &#125; public static void main(String[] args) &#123; Human man = new Man(); Human woman = new Woman(); StaticDispatch st = new StaticDispatch();st.SayHello(man); st.SayHello(woman); &#125;&#125; 输出结果： Hello guy Hello guy Human是变量的静态类型，Man是变量的实际类型，编译器在重载时依据的是变量的静态类型而不是实际类型，静态类型是编译器可知的，所以在编译阶段，javac编译器会根据静态类型选择重载版本。变量的实际类型变化结果只有在程序运行时才确定，在编译的时候无法确定一个对象的实际类型是什么。 动态分派（典型应用：重写） 在运行期根据实际类型确定方法执行版本虚拟机的虚方法表中存放各个方法实际入口地址，如果子类没有重写方法，那么子类和父类的虚方法表中同一方法的实际地址一样，如果子类重写了，则子类虚方法表中的方法实际入口地址指向子类的版本方法实际地址。 6、内存模型 1、主内存和工作内存Java内存模型规定了所有变量存储在主内存中，每条线程有自己的工作内存用于保存被该线程用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，线程的工作内存之间相互隔离，线程之间变量的值传递通过主内存完成。1、内存模型要求read和load操作、store和write操作必须顺序执行，但不要求连续执行。2、内存模型规定基本操作的几条规则： 不允许一个线程丢弃最近的assign操作，即一个变量在工作内存中改变了之后必须同步回主内存 如果对一个变量执行lock操作，会清空工作内存中该变量的值，执行引擎使用该变量之前需要执行load或assign操作初始化该变量的值 对一个变量执行unlock操作之前，必须先把变量值同步回主内存2、volatile关键字 1、volatile型变量的两个特性 保证此变量对所有线程的可见性 volatile变量在各个线程下是一致的，但由于Java运算操作的非原子性导致volatile变量在并发下的运算也是不安全的 禁止指令重排序优化2、对64位的数据类型double和long，虚拟机允许将没有被volatile修饰的64位数据读写操作分两次32位操作进行3、Volatile变量修饰符如果使用恰当的话，它比synchronized的使用和执行成本会更低，因为它不会引起线程上下文的切换和调度4、实现原理：有volatile变量修饰的共享变量进行写操作的时候会多一行以lock为前缀的汇编代码，lock前缀的指令在多核处理器下会引发了两件事情： 将当前处理器缓存行的数据会写回到系统内存。 这个写回内存的操作会引起在其他CPU里缓存了该内存地址的数据无效。 3、三个特性 原子性 可见性 一个线程对一个共享变量的修改，另一个线程能够立即得知这个修改final和synchronized也可以保证可见性 有序性 如果在本线程中，所有操作都是有序的，如果在一个线程观察另一个线程，所有操作都是无序的。 4、Java线程 1、线程的调度 协同式线程调度 线程的执行时间由线程自身控制，执行完任务后主动通知系统切换到另一个线程好处：实现简单，线程切换对线程本身是可知的，没有同步问题坏处：线程执行时间不可控，线程如果不主动通知系统切换就会一直阻塞 抢占式线程调度 每个线程由系统分配执行时间，通过设定线程优先级决定线程获得分配时间的多少Java就是这种实现2、线程的五种状态 新建（New） 运行（Runnable） 可能正在执行或者等待CPU分配时间 无限期等待（Waiting） 等待被其他线程显式唤醒 限期等待（Timed Waiting） 等待被系统自动唤醒 阻塞（Blocked） 等待获取一个排他锁 结束（Terminated） 3、线程安全Java中各种操作共享的数据分为五类： 不可变 不可变的对象一定是线程安全的比如，如果共享数据是基本类型，定义时用final修饰则数据就是不可变的。String类对象调用replace()、subString()等方法时只会返回一个新构造的字符串，本来的字符串值不受影响 绝对线程安全 相对线程安全 线程兼容 线程对立 4、线程安全的实现 互斥同步（阻塞同步） 同步是指多线程并发访问同一共享数据时保证同一时刻只能被一个线程使用；互斥是实现同步的一种手段，临界区、互斥量、信号量都是主要的互斥实现方式。Java中基本的互斥同步就是synchronized 关键字、java.util.concurrent包中的ReentrantLock（可重入锁）问题：进行线程阻塞和唤醒带来的性能问题 非阻塞同步5、内存泄漏 内存泄漏一般可以理解为系统资源（各方面的资源，堆、栈、线程等）在错误使用的情况下，导致使用完毕的资源无法回收（或没有回收），从而导致新的资源分配请求无法完成，引起系统错误。 年老代堆空间被占 java.lang.OutOfMemoryError: Java heap space 根据垃圾回收前后情况对比，同时根据对象引用情况（常见的集合对象引用）分析，基本都可以找到泄漏点。 持久代被占满 java.lang.OutOfMemoryError: PermGen space 主要原因就是大量动态反射生成的类不断被加载，最终导致Perm区被占满,，主要解决方法：设置-XX:MaxPermSize=16m；换用JDK。比如JRocket 堆栈溢出 java.lang.StackOverflowError 一般是递归没返回或者循环调用]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Synchronized关键字]]></title>
    <url>%2F2018%2F10%2F10%2FSynchronized%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[1、作用保证同一时刻只有一个线程执行该段代码，以达到保证并发安全的效果 2、两种用法 对象锁 方法锁、同步代码块锁 类锁 synchronized修饰静态的方法 指定锁位Class对象 3、类锁不管Java对象有多少个实例对象，但是只有一个class对象，通过给class对象上锁达到同步的效果 4、访问同一个对象实例的两个不同的synchronized普通方法，由于默认获取的是this锁，所以会出现串行的情况12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class SychronizedObjectMethod implements Runnable&#123; static SychronizedObjectMethod instance = new SychronizedObjectMethod(); public static void main(String[] args) &#123; Thread t1 = new Thread(instance); Thread t2 = new Thread(instance); t1.start(); t2.start(); while (t1.isAlive() | t2.isAlive()) &#123; &#125; System.out.println("finished!"); &#125; @Override public void run() &#123; if (Thread.currentThread().getName().equals("Thread-0"))&#123; method1(); &#125;else &#123; method2(); &#125; &#125; public synchronized void method1()&#123; System.out.println("我是加锁的普通同步方法1，我叫"+Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"运行结束"); &#125; public synchronized void method2()&#123; System.out.println("我是加锁的普通同步方法2，我叫"+Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"运行结束"); &#125;&#125; 当把method2加上static时，这两个方法同步时获取的锁就不是同一个锁了，所以会并行执行这两个方法 5、小结 一把锁只能同时被一个线程获取 每个实例都对应有自己的一把锁，不同的实例之间互不影响。例外：锁对象时*.class以及synchronized修饰的static方法时，所有的对象共用同一把锁 无论是方法正常执行完毕或者方法抛出异常，都会释放锁6、性质 1、可重入 同一线程的外层函数获得锁之后，内层函数可以直接再次获取该锁 可重入原理：加锁次数计数器2、不可中断（原子性）]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[泛型与容器]]></title>
    <url>%2F2018%2F10%2F08%2F%E6%B3%9B%E5%9E%8B%E4%B8%8E%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1、泛型 好处：更好的安全性、更好的可读性 Java中因为类型参数会被替换为object，所以泛型中不能用基本数据类型Pair&lt;int&gt; minmax = new Pair&lt;int&gt;(1,100)不合法 2、列表和队列 迭代的陷阱：在迭代的中间调用容器的删除方法 12345678910public void remove(ArrayList&lt;Integer&gt; list) &#123; for (Integer a : list) &#123; if (a &lt;= 100) &#123; list.remove(a) //抛出ConcurrentModificationException &#125; &#125; &#125;/**迭代器内部会维护一些索引位置相关的数据，迭代过程中容器不能发生结构性变化（添加、插入、删除），否则索引位置就失效。*/ ArrayList不是线程安全的，内部采用动态数组实现 1、可随机访问，按照索引访问效率高2、除非数组已排序，否则按照内容查找元素效率低，性能与数组长度成正比3、添加N个元素效率为O(N)，N为数组长度4、插入和删除元素效率低，因为需要移动元素，具体为O(N) LinkedList内部是双向链表实现，每个元素在内存都是单独存放 1、按需分配空间2、不可以随机访问，按照索引访问效率低3、不管是否排序，按照内容查找元素效率都低4、两端添加、删除元素效率高5、中间插入、删除元素要先定位，效率较低，但修改本身效率很高 ArrayDeque实现了双端队列，内部使用循环数组实现 1、两端添加、删除效率很高2、根据元素内容查找和删除的效率较低3、没有索引位置的概念，不能根据索引进行操作 3、Map和Set HashMap：实现Map接口，内部有一个哈希表即数组table，每个table[i]指向一个单向链表，根据键存取值，用键算出hash值，取模得到数组中的索引位置buketIndex，然后操作table[buketIndex]指向的单向链表 1、根据键存取值效率很高2、键值对没有顺序，因为hash值是随机的3、线程不安全 HashSet set是没有重复元素，不保证顺序的容器接口 与HashMap类似，HashSet要求元素重写hashCode和equals方法 实现set接口，内部利用HasnMap实现：1、没有重复元素；2、高效添加、删除元素以及判断元素是否存在；3、没有顺序 排序二叉树 TreeMap和TreeSet的实现基础 顺序特点：左子树所有节点小于该节点，右子树所有节点大于gai 基本的保存、删除、查找效率为O(h),h为树的高度 AVL树保证树的高度平衡，红黑树保证大致平衡 TreeMap 按键而不是按值有序，它要么键实现Comparable接口，要么创建时传递一个Comparator对象 内部是红黑树实现的 根据键保存、查找、删除效率较高，O(h) TreeSet 实现了：排重和有序。排重是基于比较结果的 基于TreeMap 没有重复元素 添加、删除元素，判断元素是否存在效率较高 有序 要求Comparable接口或者通过构造方法提供一个Comparator对象 LinkedHashMap HashMap的子类，内部还有一个双向链表维护键值对的顺序 插入顺序：先添加的在前面，后添加的在后面，修改操作不影响顺序 访问顺序：最末尾的是最近访问的，最开始的是最久没被访问的，因为对一个键执行get/put操作后对应的键值对会移到链表末尾 用于缓存 1、缓存就是用来保存常用的数据，容量小访问快2、LRU是缓存里一种流行的替换算法，即当缓存满了，最近最少使用的先被清理出去 内部维护一个单独的双向链表，默认是插入顺序 EnumSet：用位向量实现 位向量就是用一个位表示一个元素的状态，一组位表示一个集合的状态，每个位对应一个元素，状态只有两种 4、堆与优先级队列 堆 是完全二叉树（给定任意一个节点可以根据其编号直接快速计算出其父节点和孩子节点编号） 逻辑概念上是一颗完全二叉树，物理存储上使用数组，还有一定的顺序要求 根据顺序分为：最大堆和最小堆 最大堆：每个节点都不大于其父节点。最小堆相反 添加和删除元素的时候有两个关键的过程以保持堆的性质，一个是向上调整一个是向下调整 PriorityQueue优先级队列 队列长度没有限制，每个元素都有优先级，队头的元素优先级最高 内部用堆实现，内部元素不是完全有序的，不过逐个出队会得到有序的输出 查看头部元素效率很高，O(1),入队出队效率较高，O(log2(N)) 根据值查找和删除元素效率比较低，O(N) 求中值：元素是动态添加（用一个最大堆一个最小堆） 步骤：1、设当前中位数为m，最大堆维护&lt;=m的元素，最小堆维护&gt;=m的元素，但两个堆都不包含m2、当新元素e到达与m进行比较，若e&lt;=m将其加入最大堆，反之加入最小堆3、第2步之后如果最大堆和最小堆元素个数差&gt;=2，则将m加入元素个数少的堆中，然后从元素个数多的堆将根节点移除并赋值给m]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Java编程的逻辑</tag>
      </tags>
  </entry>
</search>
